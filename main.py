import os
import argparse
import json
import preprocess  # (ìˆ˜ì •ëœ ë²„ì „)
import ocr
import event
import audio       # (ìˆ˜ì •ëœ ë²„ì „)
from pathlib import Path

# --- (Merge ê´€ë ¨ í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€: str_time_to_sec, merge_vision_and_audio) ---
def str_time_to_sec(time_str):
    if isinstance(time_str, (int, float)): return float(time_str)
    try:
        parts = time_str.split(':')
        if len(parts) == 2: return int(parts[0]) * 60 + int(parts[1])
        elif len(parts) == 3: return int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
    except: pass
    return 0.0

def merge_vision_and_audio(vision_json_path, audio_json_path, output_json_path):
    # ... (ì•„ê¹Œ ì‘ì„±í•´ë“œë¦° ë³‘í•© ë¡œì§ê³¼ ë™ì¼) ...
    # ì½”ë“œê°€ ê¸¸ì–´ì§€ë‹ˆ ìƒëµí•©ë‹ˆë‹¤. ìœ„ ë‹µë³€ì˜ merge í•¨ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ì“°ì‹œë©´ ë©ë‹ˆë‹¤.
    # í•µì‹¬: STT ì‹œê°„ëŒ€ì™€ ê°€ì¥ ë§ì´ ê²¹ì¹˜ëŠ” Vision í™”ì ì´ë¦„ì„ ë§¤ì¹­
    
    print(f"ğŸ”„ ë°ì´í„° ë³‘í•© ì¤‘...")
    with open(vision_json_path, 'r', encoding='utf-8') as f: vision_data = json.load(f)
    with open(audio_json_path, 'r', encoding='utf-8') as f: audio_data = json.load(f)
    
    v_segs = vision_data.get("segments", [])
    for v in v_segs:
        v["_s"] = str_time_to_sec(v.get("first_seen", 0))
        v["_e"] = str_time_to_sec(v.get("last_seen", 0))
        
    for stt in audio_data.get("transcripts", []):
        s_start, s_end = stt["start"], stt["end"]
        best_spk = "Unknown"
        max_overlap = 0.0
        
        for v in v_segs:
            # Overlap ê³„ì‚°
            ov_s = max(s_start, v["_s"])
            ov_e = min(s_end, v["_e"])
            dur = max(0, ov_e - ov_s)
            if dur > max_overlap:
                max_overlap = dur
                best_spk = v["name"]
        stt["speaker"] = best_spk
        
    for v in v_segs: del v["_s"], v["_e"]
    
    vision_data["transcripts"] = audio_data.get("transcripts", [])
    
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(vision_data, f, ensure_ascii=False, indent=2)
    return output_json_path

# ==========================================
# [Main] íŒŒì´í”„ë¼ì¸
# ==========================================
def process_pipeline(video_path):
    if not os.path.exists(video_path): return None
    video_name = Path(video_path).stem
    print(f"ğŸ¬ [Project] ë¶„ì„ ì‹œì‘: {video_name}")

    # 1. ê³µí†µ ì¶œë ¥ ê²½ë¡œ ê³„ì‚°
    # data/video/test1.mp4 -> data/output/test1
    base_dir = os.path.dirname(video_path)
    output_root = os.path.join(os.path.dirname(base_dir), "output")
    final_output_dir = os.path.join(output_root, video_name)
    os.makedirs(final_output_dir, exist_ok=True)

    # =================================================
    # [Step 1] ì „ì²˜ë¦¬ (Preprocess) - ì˜¤ë””ì˜¤ & í”„ë ˆì„ ì¶”ì¶œ
    # =================================================
    # preprocess ëª¨ë“ˆì´ ë‘ ê°€ì§€ ì¼ì„ ë‹¤ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    print("--- [1ë‹¨ê³„] ì „ì²˜ë¦¬ ---")
    
    # 1-1. ì˜¤ë””ì˜¤ ì¶”ì¶œ (.wav)
    wav_path = preprocess.extract_audio(video_path)
    
    # 1-2. í”„ë ˆì„ ì¶”ì¶œ (jpg í´ë”)
    frames_dir = preprocess.split_video_to_frames(video_path)
    
    if not frames_dir or not wav_path:
        print("âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return None

    # =================================================
    # [Step 2] Vision ë¶„ì„ (OCR + Event)
    # =================================================
    print("--- [2ë‹¨ê³„] ë¹„ì „ ë¶„ì„ ---")
    ocr.run_ocr_on_folder(frames_dir, final_output_dir)
    event.run_event_detection(video_path, final_output_dir)
    
    vision_json = os.path.join(final_output_dir, "result.json")

    # =================================================
    # [Step 3] Audio ë¶„ì„ (STT)
    # =================================================
    print("--- [3ë‹¨ê³„] ì˜¤ë””ì˜¤ ë¶„ì„ ---")
    # ì „ì²˜ë¦¬ëœ wav_pathë¥¼ ë„˜ê²¨ì¤ë‹ˆë‹¤.
    stt_json = audio.run_stt(wav_path, final_output_dir)

    # =================================================
    # [Step 4] ë³‘í•© (Merge)
    # =================================================
    print("--- [4ë‹¨ê³„] ë°ì´í„° í†µí•© ---")
    if os.path.exists(vision_json) and stt_json:
        final_result = merge_vision_and_audio(vision_json, stt_json, vision_json)
        
        print("="*40)
        print(f"ğŸ‰ ëª¨ë“  ê³¼ì • ì™„ë£Œ!")
        print(f"ğŸ“„ ìµœì¢… ê²°ê³¼: {final_result}")
        print("="*40)
        return final_result
    else:
        print("âŒ ë³‘í•© ì‹¤íŒ¨: íŒŒì¼ ëˆ„ë½")
        return None

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--video", type=str, required=True)
    args = parser.parse_args()
    process_pipeline(args.video)