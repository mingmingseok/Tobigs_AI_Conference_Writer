import os
import json
import torch
import dotenv
from faster_whisper import WhisperModel

dotenv.load_dotenv()
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
COMPUTE_TYPE = "float16" if DEVICE == "cuda" else "int8"
WHISPER_MODEL_SIZE = "medium"

def run_stt(wav_path, output_dir):
    """
    Wav íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ì„œ STTë¥¼ ìˆ˜í–‰í•˜ê³  JSON ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    (ì˜¤ë””ì˜¤ ì¶”ì¶œ ê¸°ëŠ¥ì€ preprocess.pyë¡œ ì´ê´€ë¨)
    """
    if not wav_path or not os.path.exists(wav_path):
        print(f"âŒ STT ì—ëŸ¬: ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ -> {wav_path}")
        return None

    print(f"ğŸš€ [Audio] STT ë¶„ì„ ì‹œì‘ (Device: {DEVICE})")
    os.makedirs(output_dir, exist_ok=True)
    
    # Whisper ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ“ Whisper ëª¨ë¸ ë¡œë”© ì¤‘... ({WHISPER_MODEL_SIZE})")
    try:
        model = WhisperModel(WHISPER_MODEL_SIZE, device=DEVICE, compute_type=COMPUTE_TYPE)
    except Exception as e:
        print(f"âŒ Whisper ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

    # STT ìˆ˜í–‰
    print("ğŸ“ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
    segments, info = model.transcribe(wav_path, beam_size=5, language="ko", temperature=0.0)

    stt_results = []
    for i, segment in enumerate(segments):
        stt_results.append({
            "start": round(segment.start, 2),
            "end": round(segment.end, 2),
            "text": segment.text.strip(),
            "speaker": None # Merge ë‹¨ê³„ì—ì„œ ì±„ì›Œì§
        })
        if i % 20 == 0:
             print(f"  ... {segment.start:.1f}s: {segment.text[:20]}")

    # JSON ì €ì¥
    json_path = os.path.join(output_dir, "stt_result.json")
    final_data = {"transcripts": stt_results}
    
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… STT ì™„ë£Œ! JSON ì €ì¥ë¨: {json_path}")
    return json_path